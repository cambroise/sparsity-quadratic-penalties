\subsection{Group-Lasso}

We consider here the $\ell_{\infty,1}$ variant of the group-Lasso, which was
first proposed by \citet{Turlach05} to perform variable selection in the
multiple response setup.
%
A group structure is defined on
the set of variables by setting a partition of the index set
$\mathcal{I}=\{1,\ldots,p\}$, that is,
$
  \mathcal{I}=\bigcup_{k=1}^K\group \enspace,\, \text{with}\enspace 
  \group \cap \group[\ell]=\emptyset \enspace
  \text{for}\enspace k\neq\ell \enspace.
$
%
Let $p_k$ denote the cardinality of group $k$, and $\bfbeta_{\group} \in
\Rset^{p_k}$ be the vector $(\beta_j)_{j\in \group}$.
%


The $\ell_{\infty,1}$ mixed-norm of $\bfbeta$ (that is, its groupwise 
$\ell_\infty$-norm) is defined as
%
\begin{equation*}
  \uball = \left\{ 
    \bfbeta \in \mathbb{R}^p :\sum_{k=1}^K \norm[\infty]{\bfbeta_{\group}} \leq 1
  \right\}
  \enspace.
\end{equation*}
%
The dual norm is the groupwise $\ell_1$-norm:
%
\begin{align*}
  \uball[*]^\eta & = \left\{ \bfgamma \in \mathbb{R}^p :
\sup_{\bfbeta\in\uball} \bfgamma^\intercal\bfbeta \leq \eta \right\} \\
    & = \left\{ \bfgamma \in \mathbb{R}^p : \max_{k\in\{1,...,K\}}  \norm[1]{\bfgamma_{\group}} \leq \eta \right\} \\
    & = \mathbf{conv} \big\{ 
                        \left\{\eta\bfe^{p_1}_1, \ldots, \eta\bfe^{p_1}_{p_1},-\eta\bfe^{p_1}_1, \ldots, -\eta\bfe^{p_1}_{p_1} \right\} 
                        \times \ldots \\
    & \hspace*{4em} \times 
                        \left\{\eta\bfe^{p_K}_1, \ldots, \eta\bfe^{p_K}_{p_K},-\eta\bfe^{p_K}_1, \ldots, -\eta\bfe^{p_K}_{p_K} \right\} 
                      \big\}
  \enspace,
\end{align*}
where $\bfe^p_j$ is the $j$th element of the canonical basis of $\Rset^p$.
Problem \eqref{eq:general:dual} becomes:
%
\begin{align*}
  & \min_{\bfbeta\in\mathbb{R}^p} \max_{\bfgamma \in \uball[*]^\eta}
      \Big\{ \frac{1}{2} \norm{\bfX \bfbeta - \bfy}^2 + \frac{\lambda}{2} \norm{\bfbeta - \bfgamma}^2 \Big\} \\
  \Leftrightarrow
    & \min_{\bfbeta\in\mathbb{R}^p}
      \frac{1}{2} \norm{\bfX \bfbeta - \bfy}^2 + \lambda \eta \sum_{k=1}^K \norm[\infty]{\bfbeta_{\group}} + \frac{\lambda}{2} \norm{\bfbeta}^2 
  \enspace,
\end{align*}
%

Notice that the limiting cases of this penalty are two classical problems: ridge
regression and the $\ell_{\infty,1}$ group-Lasso.
A 2D pictorial illustration of this evolution is given in
Figure~\ref{fig:group-penalty}, where $\uball[*]^\eta$ is the convex hull of the
points located on the axes at $\pm \eta$, which are identified by the cross
markers.
Then, the sublevel set 
$\{\bfbeta : \max_{\bfgamma \in \uball[*]^\eta} \norm{\bfbeta-\bfgamma}^2 \leq t\}$
is simply defined as the intersection of the four sublevel sets
$\{\bfbeta : \norm{\bfbeta - \bfgamma}^2 \leq t\}$ for 
$\bfgamma=\pm \eta\bfe^{2}_1$ and $\bfgamma=\pm \eta\bfe^{2}_2$,
which are Euclidean balls centered at these $\bfgamma$ values.
%
\begin{figure}
  \begin{center} 
    \smallxylabelsquare{../figures/linf_decomposition1}{$\beta_1$}{$\beta_2$}{}%
    \smallxylabelsquare{../figures/linf_decomposition2}{$\beta_1$}{$\beta_2$}{}%
    \smallxylabelsquare{../figures/linf_decomposition3}{$\beta_1$}{$\beta_2$}{}%
    \smallxylabelsquare{../figures/linf_decomposition4}{$\beta_1$}{$\beta_2$}{}%
    \caption{Sublevel sets for the $\ell_{\infty,1}$ group-Lasso penalties in $\mathbb{R}^2$.
             In each plot, the darkest colored patch corresponds to a sublevel set $\norm[]{\bfbeta} \leq c$.
             Each set is defined as the intersection of the four Euclidean balls
             (represented as light color layers) whose centers are
             represented by crosses (not visible because out of frame on the 
             rightmost example).}
    \label{fig:group-penalty}
    \end{center} 
\end{figure}

\iffalse
The  lagrangian formulation  of the  $\ell_{\infty,1}$ version  of the
group-Lasso as a constrained optimization can be expressed as
$$
 \min_{\bfbeta}     \norm{\bfX  \bfbeta  - \bfy  }^2+\lambda \sum_{g=1}^G \|\bfbeta_g\|_\infty,
$$
with $\bfbeta_g=(\beta_{gk})$ the coefficients of $\bfbeta$ corresponding to group $g$.


The penalty term can be expressed in a form close to our adverse quadratic penalty. Let us consider  the adverse vector domain to be
$$
 \clD_{\bfgamma}=\left\{ \bfgamma \in \mathbb{R}^p | \bfgamma= 
(\alpha_j \mathbb{I}_{(\mbox{rank}\left(  \max_k |\beta|_{gk}\right)=j) })_{j=1
      \cdots p } 
\norm[\infty]{(\alpha_1,\cdots,\alpha_p)} \leq \eta_\alpha \right\} .
$$

We can reformulate the previous lagrangian as 
\begin{equation}
    \min_{\bfbeta\in\mathbb{R}^p} \max_{\bfgamma \in \clD_{\bfgamma}}
    \norm{\bfX \bfbeta - \bfy } + \lambda \norm{\bfbeta +
    \bfgamma } \enspace.
\end{equation}

This  rewriting  of the  problem  allows to  see  that  the very  same
optimization adaptive  constraint algorithm  used for the  elastic-net
can be used to solve the Group  $\ell_{\infty,1}$ problem.


{\color{red}{YG : Could'nt we derive the usual group-Lasso from the robust
optimization viewpoint, simply by changing the definition of $\clD_{\bfX}$, with
groupwise Frobenius norms?}

Christophe: Si  tu fais cela tu écris  bien le group Lasso  mais je ne
vois pas comment cela permet de faciliter la résolution du problème avec les mêmes
techniques que pour les autres....
}

{\color{blue}{Christophe:  une version group  oscar devrait  donner de
    meilleurs résultats}}
\fi