\section{Discussion}

%% SUMMARY

% PRINCIPLE
This paper presents a new viewpoint on sparsity-inducing penalties
where the dual norms associated with these penalties play a central role. 
Our formulation can be seen as a dual formulation of the original problem
where the dual variables defines a series of quadratic convex set the
intersection of which defines the feasible set of the original
problem.

This  viewpoint  enables  to  cast   in  the  same  framework  several
well-known penalties. In particular, we detailed how the Lasso and the
group-Lasso (with the $\ell_{\infty,1}$  mixed norm), possibly applied
together with an  $\ell_2$ ridge penalty (leading to what  is known as
the elastic net for the Lasso) can be derived. 
\\

% ALGORITHM AND MAGIC BOUND
We derived a  general-purpose algorithm that computes  the solution to
their companion  penalized regression problem,  and to obtain  a lower
bound  on the  minimum  of  the objective  function  that provides  an
assessment of convergence.  The proposed  algorithm solves a series of
quadratic  problems defined  from  the dual  variables.   It has  been
thoroughly tested  and compared with  state-of-the-art implementations
for the elastic  net and the Lasso, comparing favorably  in most cases
to all its competitors.%
\\

% DISCUSSION
From a  practical viewpoint, an  important feature of our  approach is
that it solves the original problem  up to machine precision: we shown
that when  variable selection  is involved,  optimization with  a high
level of precision is mandatory to recover the true model.
% Moreover, our algorithm  is well suited for computing  a solution path
% rather than  for just one  value of $\lambda_1, (\lambda_2)$  since we
% are  generally interested  in cross-validating  these paths  for model
% selection purpose (at least in genomics).
\\

% FUTURE DEV
Regarding  future  development,  the   algorithm  can  be  adapted  to
non-quadratic loss  functions for  addressing other  learning problems
such  as  classification,  but  this  generalization,  which  requires
solving non-quadratic  problems, may not  be as efficient  compared to
the  existing alternatives.   We are  now examining  how to  address a
wider range of penalties by extending the framework in two directions:
first,  to accommodate  additional general  $\ell_2$ penalties  in the
form of  arbitrary symmetric  positive semidefinite matrix  instead of
the simple ridge, in particular to provide an efficient implementation
of the  structured elastic  net \citep{2010_AOS_Slawski} ;  second, we
plan to  derive similar  views on a  wider range  of sparsity-inducing
penalties, such as the fused-Lasso or the OSCAR \citep{Bondell08}.
